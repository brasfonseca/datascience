{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPzDJRlpoqNb7vrdvydZOX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brasfonseca/datascience/blob/main/MetricasAvaliacaoAprendizado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Principais métricas para avaliação de modelos de classificação de dados, como acurácia, sensibilidade (recall), especificidade, precisão e F-score**"
      ],
      "metadata": {
        "id": "VGzgPpZ8IH0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Diagnóstico de Câncer**"
      ],
      "metadata": {
        "id": "IWg9kOVDIwYl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGYfNPKpHiZD",
        "outputId": "61075a5a-02a5-4392-f00e-11529e1a5499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusão:\n",
            "[[3 1]\n",
            " [1 5]]\n",
            "Acurácia: 0.80\n",
            "Precisão: 0.83\n",
            "Sensibilidade (Recall): 0.83\n",
            "Especificidade: 0.75\n",
            "F-score: 0.83\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Exemplo de rótulos verdadeiros e previsões do modelo\n",
        "y_true = [1, 1, 1, 0, 0, 0, 1, 0, 1, 1]  # Valores reais (1: câncer, 0: saudável)\n",
        "y_pred = [1, 0, 1, 0, 0, 1, 1, 0, 1, 1]  # Previsões do modelo\n",
        "\n",
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(cm)\n",
        "\n",
        "# Acurácia\n",
        "acuracia = accuracy_score(y_true, y_pred)\n",
        "print(f'Acurácia: {acuracia:.2f}')\n",
        "\n",
        "# Precisão\n",
        "precisao = precision_score(y_true, y_pred)\n",
        "print(f'Precisão: {precisao:.2f}')\n",
        "\n",
        "# Sensibilidade (Recall)\n",
        "sensibilidade = recall_score(y_true, y_pred)\n",
        "print(f'Sensibilidade (Recall): {sensibilidade:.2f}')\n",
        "\n",
        "# Especificidade\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "especificidade = tn / (tn + fp)\n",
        "print(f'Especificidade: {especificidade:.2f}')\n",
        "\n",
        "# F-score\n",
        "f_score = f1_score(y_true, y_pred)\n",
        "print(f'F-score: {f_score:.2f}')"
      ]
    }
  ]
}